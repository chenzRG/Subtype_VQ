{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNF\n",
    "\n",
    "SNF <- function(Wall, K=20, t=20) {\n",
    "    # Similarity Network Fusion takes multiple views of a network (Wall) and\n",
    "    # fuses them together to create a overall affinity matrix.\n",
    "    #\n",
    "    # Args:\n",
    "    #   Wall: List of matrices, each element is a square symmetric affinity \n",
    "    #       matrix.\n",
    "    #   K: Number of neighbors used in the K-nearest neighbours step,??? more details???\n",
    "    #   t: Number of iterations for the diffusion process\n",
    "    #\n",
    "    # Returns:  \n",
    "    #   W: Unified similarity graph of all data types in Wall. \n",
    "\n",
    "    check_wall_names <- function(Wall){\n",
    "        # Checks if dimnames are consistant across all matrices in Wall\n",
    "        #   #Move to internal functions?\n",
    "        # Args:\n",
    "        #   Wall: List of matrices\n",
    "        # Returns:\n",
    "        #   logical: True/False indicator of dimnames equivalence\n",
    "        name_match <- function(names_A, names_B){\n",
    "            return(identical(dimnames(names_A), dimnames(names_B)))\n",
    "        }\n",
    "\n",
    "        return(all(unlist(lapply(Wall, FUN=name_match, Wall[[1]]))))\n",
    "    }\n",
    "\n",
    "    #Check if Wall names are consistant across all matrices in Wall\n",
    "    wall.name.check <- check_wall_names(Wall)\n",
    "    wall.names <- dimnames(Wall[[1]])\n",
    "    if(!wall.name.check){\n",
    "        warning(\"Dim names not consistent across all matrices in Wall.\n",
    "            Returned matrix will have no dim names.\")\n",
    "    }\n",
    " \n",
    "    LW <- length(Wall)\n",
    "\n",
    "    #Normalization method for affinity matrices\n",
    "    normalize <- function(X){\n",
    "        row.sum.mdiag <- rowSums(X) - diag(X) \n",
    "        #If rowSumx(X) == diag(X), set row.sum.mdiag to 1 to avoid div by zero\n",
    "        row.sum.mdiag[row.sum.mdiag == 0] <- 1   \n",
    "        X <- X/(2*(row.sum.mdiag))\n",
    "        diag(X) <- 0.5\n",
    "        return(X)\n",
    "    }\n",
    "    \n",
    "    #Normalize different networks to avoid scale problems.\n",
    "    newW <- vector(\"list\", LW)\n",
    "    nextW <- vector(\"list\", LW)\n",
    "    for(i in 1:LW){\n",
    "      Wall[[i]] <- normalize(Wall[[i]])\n",
    "      Wall[[i]] <- (Wall[[i]] + t(Wall[[i]]))/2\n",
    "    }\n",
    "    \n",
    "    ### Calculate the local transition matrix. (KNN step?)\n",
    "    for(i in 1:LW){\n",
    "      newW[[i]] <- (.dominateset(Wall[[i]], K))\n",
    "    }\n",
    "    \n",
    "    #Perform the diffusion for t iterations\n",
    "    for (i in 1:t) {\n",
    "        for(j in 1:LW){\n",
    "            sumWJ <- matrix(0,dim(Wall[[j]])[1], dim(Wall[[j]])[2])\n",
    "            for(k in 1:LW){\n",
    "                if(k != j) {\n",
    "                    sumWJ <- sumWJ + Wall[[k]]\n",
    "                }\n",
    "            }\n",
    "            nextW[[j]] <- newW[[j]] %*% (sumWJ/(LW-1)) %*% t(newW[[j]])\n",
    "        }\n",
    "\n",
    "        #Normalize each new obtained networks.\n",
    "        for(j in 1 : LW){\n",
    "          Wall[[j]] <- normalize(nextW[[j]])\n",
    "          Wall[[j]] <- (Wall[[j]] + t(Wall[[j]]))/2;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Construct the combined affinity matrix by summing diffused matrices\n",
    "    W <- matrix(0, nrow(Wall[[1]]), ncol(Wall[[1]]))\n",
    "    for(i in 1:LW){\n",
    "        W <- W + Wall[[i]]\n",
    "    }\n",
    "\n",
    "    W <- W/LW\n",
    "    W <- normalize(W)\n",
    "    W <- (W + t(W)) / 2\n",
    "\n",
    "    if(wall.name.check){\n",
    "        dimnames(W) <- wall.names\n",
    "    } \n",
    "\n",
    "    return(W)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b164cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEMO\n",
    "\n",
    "raw.data.to.similarity <- function(raw.data) {\n",
    "  return(lapply(raw.data, function(x) {return(cor(as.matrix(x), as.matrix(x)))}))\n",
    "}\n",
    "\n",
    "normalize.matrix <- function(data.matrix) {\n",
    "  temp = data.matrix - rowMeans(data.matrix)\n",
    "  should.keep = (apply(temp, 1, sd) != 0)\n",
    "  return ((temp / apply(temp, 1, sd))[should.keep, ])\n",
    "}\n",
    "\n",
    "#' @title NEMO num clusters\n",
    "#' @name nemo.num.clusters\n",
    "#' @description Estimates the number of clusters in an affinity graph.\n",
    "#' @param W the affinity graph.\n",
    "#' @param NUMC possible values for the number of clusters. Defaults to 2:15.\n",
    "#' @return the estimated number of clusters in the graph.\n",
    "#' @export\n",
    "nemo.num.clusters <- function(W, NUMC=2:15) {\n",
    "  if (min(NUMC) == 1) {\n",
    "    warning(\"Note that we always assume there are more than one cluster.\")\n",
    "    NUMC = NUMC[NUMC > 1]\n",
    "  }\n",
    "  W = (W + t(W))/2\n",
    "  diag(W) = 0\n",
    "  if (length(NUMC) > 0) {\n",
    "    degs = rowSums(W)\n",
    "    degs[degs == 0] = .Machine$double.eps\n",
    "    D = diag(degs)\n",
    "    L = D - W\n",
    "    Di = diag(1/sqrt(degs))\n",
    "    L = Di %*% L %*% Di\n",
    "    print(dim(L))\n",
    "    eigs = eigen(L)\n",
    "    eigs_order = sort(eigs$values, index.return = T)$ix\n",
    "    eigs$values = eigs$values[eigs_order]\n",
    "    eigs$vectors = eigs$vectors[, eigs_order]\n",
    "    eigengap = abs(diff(eigs$values))\n",
    "    eigengap = (1:length(eigengap)) * eigengap\n",
    "\n",
    "    t1 <- sort(eigengap[NUMC], decreasing = TRUE, index.return = T)$ix\n",
    "    return(NUMC[t1[1]])\n",
    "  }\n",
    "}\n",
    "\n",
    "#' @title Spectral clustering\n",
    "#' @name spectralClustering\n",
    "#' @export\n",
    "spectralClustering = SNFtool::spectralClustering\n",
    "\n",
    "\n",
    "#' @title Num neighbors ratio\n",
    "#' @name NUM.NEIGHBORS.RATIO\n",
    "#' @export\n",
    "NUM.NEIGHBORS.RATIO = 6\n",
    "\n",
    "#' @title NEMO affinity graph\n",
    "#' @name nemo.affinity.graph\n",
    "#' @description Constructs a single affinity graph measuring similarity across different omics.\n",
    "#' @param raw.data A list of the data to be clustered, where each an entry is a matrix of features x samples.\n",
    "#' @param k The number of neighbors to use for each omic. It can either be a number, a list of numbers\n",
    "#' or NA. If it is a number, this is the number of neighbors used for all omics. If this is a list,\n",
    "#' the number of neighbors are taken for each omic from that list. If it is NA, each omic chooses the\n",
    "#' number of neighbors to be the number of samples divided by NUM.NEIGHBORS.RATIO.\n",
    "#' @return A single matrix measuring similarity between the samples across all omics.\n",
    "#' @export\n",
    "nemo.affinity.graph <- function(raw.data, k=NA) {\n",
    "  if (is.na(k)) {\n",
    "    k = as.numeric(lapply(1:length(raw.data), function(i) round(ncol(raw.data[[i]]) / NUM.NEIGHBORS.RATIO)))\n",
    "  } else if (length(k) == 1) {\n",
    "    k = rep(k, length(raw.data))\n",
    "  }\n",
    "  sim.data = lapply(1:length(raw.data), function(i) {affinityMatrix(dist2(as.matrix(t(raw.data[[i]])),\n",
    "                                                                as.matrix(t(raw.data[[i]]))), k[i], 0.5)})\n",
    "  affinity.per.omic = lapply(1:length(raw.data), function(i) {\n",
    "    sim.datum = sim.data[[i]]\n",
    "    non.sym.knn = apply(sim.datum, 1, function(sim.row) {\n",
    "      returned.row = sim.row\n",
    "      threshold = sort(sim.row, decreasing = T)[k[i]]\n",
    "      returned.row[sim.row < threshold] = 0\n",
    "      row.sum = sum(returned.row)\n",
    "      returned.row[sim.row >= threshold] = returned.row[sim.row >= threshold] / row.sum\n",
    "      return(returned.row)\n",
    "    })\n",
    "    sym.knn = non.sym.knn + t(non.sym.knn)\n",
    "    return(sym.knn)\n",
    "  })\n",
    "  patient.names = Reduce(union, lapply(raw.data, colnames))\n",
    "  num.patients = length(patient.names)\n",
    "  returned.affinity.matrix = matrix(0, ncol = num.patients, nrow=num.patients)\n",
    "  rownames(returned.affinity.matrix) = patient.names\n",
    "  colnames(returned.affinity.matrix) = patient.names\n",
    "\n",
    "  shared.omic.count = matrix(0, ncol = num.patients, nrow=num.patients)\n",
    "  rownames(shared.omic.count) = patient.names\n",
    "  colnames(shared.omic.count) = patient.names\n",
    "\n",
    "  for (j in 1:length(raw.data)) {\n",
    "    curr.omic.patients = colnames(raw.data[[j]])\n",
    "    returned.affinity.matrix[curr.omic.patients, curr.omic.patients] = returned.affinity.matrix[curr.omic.patients, curr.omic.patients] + affinity.per.omic[[j]][curr.omic.patients, curr.omic.patients]\n",
    "    shared.omic.count[curr.omic.patients, curr.omic.patients] = shared.omic.count[curr.omic.patients, curr.omic.patients] + 1\n",
    "  }\n",
    "\n",
    "  final.ret = returned.affinity.matrix / shared.omic.count\n",
    "  lower.tri.ret = final.ret[lower.tri(final.ret)]\n",
    "  final.ret[shared.omic.count == 0] = mean(lower.tri.ret[!is.na(lower.tri.ret)])\n",
    "\n",
    "  return(final.ret)\n",
    "}\n",
    "\n",
    "#' @title NEMO clustering\n",
    "#' @name nemo.clustering\n",
    "#' @description Performs multi-omic clustering on a datset using the NEMO algorithm.\n",
    "#' Uses nemo.num.clusters to estimate the number of clusters.\n",
    "#' @param omics.list A list of the data to be clustered, where each an entry is a matrix of features x samples.\n",
    "#' @param k The number of neighbors to use for each omic. It can either be a number, a list of numbers\n",
    "#' or NA. If it is a number, this is the number of neighbors used for all omics. If this is a list,\n",
    "#' the number of neighbors are taken for each omic from that list. If it is NA, each omic chooses the\n",
    "#' number of neighbors to be the number of samples divided by NUM.NEIGHBORS.RATIO.\n",
    "#' @return A single matrix measuring similarity between the samples across all omics.\n",
    "#' @export\n",
    "nemo.clustering <- function(omics.list, num.clusters=NULL, num.neighbors=NA) {\n",
    "  if (is.null(num.clusters)) {\n",
    "    num.clusters = NA\n",
    "  }\n",
    "\n",
    "  graph = nemo.affinity.graph(omics.list, k = num.neighbors)\n",
    "  if (is.na(num.clusters)) {\n",
    "    num.clusters = nemo.num.clusters(graph)\n",
    "  }\n",
    "  clustering = spectralClustering(graph, num.clusters)\n",
    "  names(clustering) = colnames(graph)\n",
    "  return(clustering)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99715cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moCluster\n",
    "\n",
    "getMoCluster <- function(data       = NULL,\n",
    "                         N.clust    = NULL,\n",
    "                         type       = rep(\"gaussian\", length(data)),\n",
    "                         ncomp      = NULL,\n",
    "                         method     = \"CPCA\",\n",
    "                         option     = \"lambda1\",\n",
    "                         k          = 10,\n",
    "                         center     = TRUE,\n",
    "                         scale      = TRUE,\n",
    "                         clusterAlg = \"ward.D\"){\n",
    "\n",
    "  # check data\n",
    "  n_dat <- length(data)\n",
    "  if(n_dat > 6){\n",
    "    stop('current verision of MOVICS can support up to 6 datasets.')\n",
    "  }\n",
    "  if(n_dat < 2){\n",
    "    stop('current verision of MOVICS needs at least 2 omics data.')\n",
    "  }\n",
    "\n",
    "  useless.argument <- type\n",
    "  if(!is.element(method, c(\"CPCA\",\"GCCA\",\"MCIA\"))) {\n",
    "    stop(\"method should be one of CPCA [consensus PCA], GCCA [generalized canonical correlation analysis], or MCIA [multiple co-inertia analysis]!\")\n",
    "  }\n",
    "\n",
    "  if(is.null(ncomp)) {\n",
    "    ncomp = N.clust\n",
    "  }\n",
    "\n",
    "  moas <- data %>% mogsa::mbpca(ncomp      = ncomp,\n",
    "                                k          = k,\n",
    "                                method     = switch(method,\n",
    "                                                    \"CPCA\" = \"globalScore\",\n",
    "                                                    \"GCCA\" = \"blockScore\",\n",
    "                                                    \"MCIA\" = \"blockLoading\"),\n",
    "                                option     = option,\n",
    "                                center     = center,\n",
    "                                scale      = scale,\n",
    "                                moa        = TRUE,\n",
    "                                svd.solver = \"fast\",\n",
    "                                maxiter    = 1000,\n",
    "                                verbose    = FALSE)\n",
    "\n",
    "  scrs <- moas %>% moaScore\n",
    "  dist <- scrs %>% dist\n",
    "  clust.dend <- hclust(dist, method = clusterAlg)\n",
    "\n",
    "  clustres <- data.frame(samID = colnames(data[[1]]),\n",
    "                         clust = cutree(clust.dend,k = N.clust),\n",
    "                         row.names = colnames(data[[1]]),\n",
    "                         stringsAsFactors = FALSE)\n",
    "  #clustres <- clustres[order(clustres$clust),]\n",
    "  message(\"clustering done...\")\n",
    "\n",
    "\n",
    "  featres <- moas@loading[which(moas@loading[,1] != 0),]\n",
    "  f <- sub('_[^_]*$', '', rownames(featres))\n",
    "  d <- sub('.*_', '', rownames(featres))\n",
    "  featres <- data.frame(feature = f,\n",
    "                        dataset = d,\n",
    "                        load = featres[,1],\n",
    "                        stringsAsFactors = FALSE)\n",
    "  feat.res <- NULL\n",
    "  for (d in unique(featres$dataset)) {\n",
    "    tmp <- featres[which(featres$dataset == d),]\n",
    "    feat.res <- rbind.data.frame(feat.res,tmp)\n",
    "  }\n",
    "  message(\"feature selection done...\")\n",
    "\n",
    "  return(list(fit = moas, clust.res = clustres, feat.res = feat.res, clust.dend = clust.dend, mo.method = \"MoCluster\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25550272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIMLR\n",
    "\n",
    "getCIMLR <- function(data        = NULL,\n",
    "                     N.clust     = NULL,\n",
    "                     type        = rep(\"gaussian\", length(data)),\n",
    "                     cores.ratio = 0,\n",
    "                     verbose     = TRUE){\n",
    "\n",
    "  # check data\n",
    "  n_dat <- length(data)\n",
    "  if(n_dat > 6){\n",
    "    stop('current verision of MOVICS can support up to 6 datasets.')\n",
    "  }\n",
    "  if(n_dat < 2){\n",
    "    stop('current verision of MOVICS needs at least 2 omics data.')\n",
    "  }\n",
    "\n",
    "  useless.argument <- type\n",
    "  if(verbose) {\n",
    "    fit <- quiet(CIMLR(data,\n",
    "                       c= N.clust,\n",
    "                       cores.ratio = cores.ratio))\n",
    "  } else {\n",
    "    fit <- CIMLR(data,\n",
    "                 c= N.clust,\n",
    "                 cores.ratio = cores.ratio)\n",
    "  }\n",
    "\n",
    "  message(\"clustering done...\")\n",
    "  input_dat <- do.call(rbind,lapply(seq(along = data), function(x){\n",
    "    ddd <- data[[x]]\n",
    "    rownames(ddd) <- paste(rownames(ddd), names(data)[x], sep = \"+\")\n",
    "    ddd\n",
    "  }))\n",
    "\n",
    "  if(verbose) {\n",
    "    ranks <- quiet(CIMLR_Feature_Ranking(A = fit$S, X = input_dat))\n",
    "  } else {\n",
    "    ranks <- CIMLR_Feature_Ranking(A = fit$S, X = input_dat)\n",
    "  }\n",
    "  ranks$names <- rownames(input_dat)[ranks$aggR]\n",
    "  fit$selectfeatures <- ranks\n",
    "  message(\"feature selection done...\")\n",
    "\n",
    "  clustres <- data.frame(samID = colnames(data[[1]]),\n",
    "                         clust = fit$y$cluster,\n",
    "                         row.names = colnames(data[[1]]),\n",
    "                         stringsAsFactors = FALSE)\n",
    "  #clustres <- clustres[order(clustres$clust),]\n",
    "\n",
    "  f <- sapply(strsplit(ranks$name, \"+\",fixed = TRUE), \"[\",1)\n",
    "  d <- sapply(strsplit(ranks$name, \"+\",fixed = TRUE), \"[\",2)\n",
    "\n",
    "  featres <- data.frame(feature = f,\n",
    "                        dataset = d,\n",
    "                        pvalue = ranks$pval,\n",
    "                        stringsAsFactors = FALSE)\n",
    "  feat.res <- NULL\n",
    "  for (d in unique(featres$dataset)) {\n",
    "    tmp <- featres[which(featres$dataset == d),]\n",
    "    tmp <- tmp[order(tmp$pvalue, decreasing = FALSE),]\n",
    "    tmp$rank <- 1:nrow(tmp)\n",
    "    feat.res <- rbind.data.frame(feat.res,tmp)\n",
    "  }\n",
    "\n",
    "  return(list(fit = fit, clust.res = clustres, feat.res = feat.res, mo.method = \"CIMLR\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iClusterBayes\n",
    "totalBICbayes = function(Data,meanZ,ndt,K,pp.cutoff){\n",
    "    BIC = 0\n",
    "    for(i in 1:ndt){\n",
    "    #sigID = which(Data[[i]]$Ratio >= quantile(Data[[i]]$Ratio,prob=0.5))\n",
    "        sigID = which(Data[[i]]$Ratio > pp.cutoff)\n",
    "        lenp = length(sigID)\n",
    "        if(lenp > 0){\n",
    "            if(Data[[i]]$type == 1){  # normal #\n",
    "                fit1 = .C(\"logNormAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[sigID]),\n",
    "                    as.double(Data[[i]]$Beta[sigID,]),as.double(Data[[i]]$sigma2[sigID]),as.double(Data[[i]]$con[,sigID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit1$loglike + (lenp*(K+1))*log(Data[[i]]$n)\n",
    "            }else if(Data[[i]]$type == 2){ # binomial #\n",
    "                fit2 = .C(\"logBinomAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[sigID]),\n",
    "                    as.double(Data[[i]]$Beta[sigID,]),as.integer(Data[[i]]$cat[,sigID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit2$loglike +  (lenp*(K+1))*log(Data[[i]]$n)\n",
    "            }else if(Data[[i]]$type == 3){ # Poisson #\n",
    "                fit3 = .C(\"logPoissonAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[sigID]),\n",
    "                    as.double(Data[[i]]$Beta[sigID,]),as.integer(Data[[i]]$cat[,sigID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit3$loglike + (lenp*(K+1))*log(Data[[i]]$n)\n",
    "            }\n",
    "        }\n",
    "        noiseID = which(Data[[i]]$Ratio <= pp.cutoff)\n",
    "        lenp = length(noiseID)\n",
    "        ZeroBeta = matrix(0,nrow=lenp,ncol=K)\n",
    "        if(lenp > 0){\n",
    "            if(Data[[i]]$type == 1){  # normal #\n",
    "                fit1 = .C(\"logNormAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[noiseID]),\n",
    "                    as.double(ZeroBeta),as.double(Data[[i]]$sigma2[noiseID]),as.double(Data[[i]]$con[,noiseID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit1$loglike + (lenp)*log(Data[[i]]$n)\n",
    "            }else if(Data[[i]]$type == 2){ # binomial #\n",
    "                fit2 = .C(\"logBinomAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[noiseID]),\n",
    "                    as.double(ZeroBeta),as.integer(Data[[i]]$cat[,noiseID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit2$loglike +  (lenp)*log(Data[[i]]$n)\n",
    "            }else if(Data[[i]]$type == 3){ # Poisson #\n",
    "                fit3 = .C(\"logPoissonAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha[noiseID]),\n",
    "                    as.double(ZeroBeta),as.integer(Data[[i]]$cat[,noiseID]),\n",
    "                    as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "                BIC = BIC - 2*fit3$loglike + (lenp)*log(Data[[i]]$n)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    BIC\n",
    "}\n",
    "\n",
    "#function to calculate deviance ratio \n",
    "dev.ratio.bayes = function(Data,meanZ,ndt,K,pp.cutoff){\n",
    "    #cat(\"- deviance ratio -\\n\")\n",
    "    loglike = 0\n",
    "    loglikeNull = 0\n",
    "    loglikeFull = 0\n",
    "    for(i in 1:ndt){\n",
    "        sigID = which(Data[[i]]$Ratio > pp.cutoff)\n",
    "        lenp=nrow(Data[[i]]$Beta)\n",
    "        ZeroBeta = matrix(0,nrow=lenp,ncol=K)\n",
    "        Beta = ZeroBeta\n",
    "        Beta[sigID,] = Data[[i]]$Beta[sigID,]\n",
    "        #cat(lenp,\"\\n\")\n",
    "        if(Data[[i]]$type == 1){  # normal #\n",
    "            fit1 = .C(\"logNormAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Beta),as.double(Data[[i]]$sigma2),as.double(Data[[i]]$con),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglike = loglike + fit1$loglike\n",
    "            fit0 = .C(\"logNormAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(ZeroBeta),as.double(Data[[i]]$sigma2),as.double(Data[[i]]$con),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglikeNull = loglikeNull + fit0$loglike\n",
    "            fit2 = .C(\"logNormAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Data[[i]]$Beta),as.double(Data[[i]]$sigma2),as.double(Data[[i]]$con),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglikeFull = loglikeFull + fit2$loglike\n",
    "        }else if(Data[[i]]$type == 2){ # binomial #\n",
    "            fit1 = .C(\"logBinomAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Beta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglike = loglike + fit1$loglike\n",
    "            #cat(fit1$loglike,\"\\n\")\n",
    "            fit0 = .C(\"logBinomAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(ZeroBeta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")           \n",
    "            loglikeNull = loglikeNull + fit0$loglike\n",
    "            fit2 = .C(\"logBinomAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Data[[i]]$Beta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglikeFull = loglikeFull + fit2$loglike            \n",
    "            #cat(fit0$loglike,\"\\n\")\n",
    "        }else if(Data[[i]]$type == 3){ # Poisson #\n",
    "            fit1 = .C(\"logPoissonAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Beta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglike = loglike + fit1$loglike\n",
    "            fit0 = .C(\"logPoissonAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(ZeroBeta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglikeNull = loglikeNull + fit0$loglike\n",
    "            fit2 = .C(\"logPoissonAll\",loglike = double(1),as.double(meanZ),as.double(Data[[i]]$Alpha),\n",
    "                as.double(Data[[i]]$Beta),as.integer(Data[[i]]$cat),\n",
    "                as.integer(Data[[i]]$n),as.integer(lenp),as.integer(K),PACKAGE=\"iClusterPlus\")\n",
    "            loglikeFull = loglikeFull + fit2$loglike                 \n",
    "        }\n",
    "    }\n",
    "    #(loglike-loglikeNull)/(loglikeFull-loglikeNull)\n",
    "    1-loglike/loglikeNull\n",
    "}\n",
    "\n",
    "\n",
    "mcmcBayes <- function(dt1,dt2=NULL,dt3=NULL,dt4=NULL,dt5=NULL,dt6=NULL,ndt,z.sdev,n,K,zBurnin,zDraw,betaBurnin,betaDraw,\n",
    "                      thin,pg,beta0,invSigma0,invSigmaBeta0,invga0,invgb0,betaVarScale){\n",
    "  \n",
    "  if(missing(dt1)){\n",
    "    stop(\"Error: dt1 is missing \\n\")\n",
    "  }\n",
    "\n",
    "  if(ndt < 1){\n",
    "      stop(\"Error: ndt must be >= 1!\")\n",
    "  }\n",
    "\n",
    "  ty = rep(0,6)\n",
    "  p = rep(1,6)\n",
    "  C = rep(1,6)\n",
    "  a = as.list(1:6)\n",
    "  b = as.list(1:6)\n",
    "  con = as.list(1:6)\n",
    "  cat = as.list(1:6)\n",
    "  class = as.list(1:6)\n",
    "  sigma2 = as.list(1:6)\n",
    "  nclass = as.list(1:6)\n",
    "  gamma = as.list(1:6)\n",
    "  acceptBeta = as.list(1:6)\n",
    "  acceptGamma = as.list(1:6)\n",
    "\n",
    "  if(ndt>0){\n",
    "    ty[1] = dt1$type\n",
    "    p[1] = dt1$p\n",
    "    C[1] = dt1$C\n",
    "    a[[1]] = dt1$Alpha\n",
    "    b[[1]] = dt1$Beta\n",
    "    if(dt1$type == 4){\n",
    "      b[[1]] = t(dt1$Beta)  #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[1]] = dt1$class\n",
    "      nclass[[1]] = dt1$nclass\n",
    "    }\n",
    "    if(dt1$type == 1){\n",
    "        con[[1]] = dt1$con\n",
    "        sigma2[[1]] = dt1$sigma2\n",
    "    }else{\n",
    "        cat[[1]] = dt1$cat\n",
    "        sigma2[[1]] = dt1$sigma2\n",
    "    }\n",
    "    gamma[[1]] = dt1$gamma\n",
    "    acceptBeta[[1]] = dt1$acsBeta\n",
    "    acceptGamma[[1]] = dt1$acsGamma\n",
    "  }\n",
    "  \n",
    "  if(ndt>1){\n",
    "    ty[2] = dt2$type\n",
    "    p[2] = dt2$p\n",
    "    C[2] = dt2$C\n",
    "    a[[2]] = dt2$Alpha\n",
    "    b[[2]] = dt2$Beta\n",
    "    if(dt2$type == 4){\n",
    "      b[[2]] = t(dt2$Beta)   #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[2]] = dt2$class\n",
    "      nclass[[2]] = dt2$nclass      \n",
    "    }\n",
    "     \n",
    "    if(dt2$type == 1){\n",
    "      con[[2]] = dt2$con\n",
    "      sigma2[[2]] = dt2$sigma2\n",
    "    }else{\n",
    "        cat[[2]] = dt2$cat\n",
    "        sigma2[[2]] = dt2$sigma2\n",
    "    }\n",
    "    gamma[[2]] = dt2$gamma\n",
    "    acceptBeta[[2]] = dt2$acsBeta\n",
    "    acceptGamma[[2]] = dt2$acsGamma\n",
    "  }\n",
    "   \n",
    "  if(ndt>2){\n",
    "    ty[3] = dt3$type\n",
    "    p[3] = dt3$p\n",
    "    C[3] = dt3$C\n",
    "    a[[3]] = dt3$Alpha\n",
    "    b[[3]] = dt3$Beta\n",
    "    if(dt3$type == 4){\n",
    "      b[[3]] = t(dt3$Beta)  #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[3]] = dt3$class\n",
    "      nclass[[3]] = dt3$nclass      \n",
    "    }\n",
    "    \n",
    "    if(dt3$type == 1){\n",
    "      con[[3]] = dt3$con\n",
    "      sigma2[[3]] = dt3$sigma2\n",
    "    }else{\n",
    "        cat[[3]] = dt3$cat\n",
    "        sigma2[[3]] = dt3$sigma2\n",
    "    }\n",
    "    gamma[[3]] = dt3$gamma\n",
    "    acceptBeta[[3]] = dt3$acsBeta\n",
    "    acceptGamma[[3]] = dt3$acsGamma\n",
    "  }\n",
    "   \n",
    "  if(ndt>3){\n",
    "    ty[4] = dt4$type\n",
    "    p[4] = dt4$p\n",
    "    C[4] = dt4$C\n",
    "    a[[4]] = dt4$Alpha\n",
    "    b[[4]] = dt4$Beta\n",
    "    if(dt4$type == 4){\n",
    "      b[[4]] = t(dt4$Beta)  #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[4]] = dt4$class\n",
    "      nclass[[4]] = dt4$nclass      \n",
    "    }\n",
    "     \n",
    "    if(dt4$type == 1){\n",
    "      con[[4]] = dt4$con\n",
    "      sigma2[[4]] = dt4$sigma2\n",
    "    }else{\n",
    "        cat[[4]] = dt4$cat\n",
    "        sigma2[[4]] = dt4$sigma2\n",
    "    }\n",
    "    gamma[[4]] = dt4$gamma\n",
    "    acceptBeta[[4]] = dt4$acsBeta\n",
    "    acceptGamma[[4]] = dt4$acsGamma\n",
    "}\n",
    "\n",
    "  if(ndt>4){\n",
    "    ty[5] = dt5$type\n",
    "    p[5] = dt5$p\n",
    "    C[5] = dt5$C\n",
    "    a[[5]] = dt5$Alpha\n",
    "    b[[5]] = dt5$Beta\n",
    "    if(dt5$type == 5){\n",
    "      b[[5]] = t(dt5$Beta)  #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[5]] = dt5$class\n",
    "      nclass[[5]] = dt5$nclass      \n",
    "    }\n",
    "     \n",
    "    if(dt5$type == 1){\n",
    "      con[[5]] = dt5$con\n",
    "      sigma2[[5]] = dt5$sigma2\n",
    "    }else{\n",
    "        cat[[5]] = dt5$cat\n",
    "        sigma2[[5]] = dt5$sigma2\n",
    "    }\n",
    "    gamma[[5]] = dt5$gamma\n",
    "    acceptBeta[[5]] = dt5$acsBeta\n",
    "    acceptGamma[[5]] = dt5$acsGamma\n",
    "  }\n",
    "\n",
    "  if(ndt>5){\n",
    "    ty[6] = dt6$type\n",
    "    p[6] = dt6$p\n",
    "    C[6] = dt6$C\n",
    "    a[[6]] = dt6$Alpha\n",
    "    b[[6]] = dt6$Beta\n",
    "    if(dt6$type == 6){\n",
    "      b[[6]] = t(dt6$Beta)  #Beta must be transposed for logMult function in giCluster.c\n",
    "      class[[6]] = dt6$class\n",
    "      nclass[[6]] = dt6$nclass      \n",
    "    }\n",
    "     \n",
    "    if(dt6$type == 1){\n",
    "      con[[6]] = dt6$con\n",
    "      sigma2[[6]] = dt6$sigma2\n",
    "    }else{\n",
    "        cat[[6]] = dt6$cat\n",
    "        sigma2[[6]] = dt6$sigma2\n",
    "    }\n",
    "    gamma[[6]] = dt6$gamma\n",
    "    acceptBeta[[6]] = dt6$acsBeta\n",
    "    acceptGamma[[6]] = dt6$acsGamma\n",
    "  }\n",
    "\n",
    "  \n",
    "  meanZ = matrix(0,nrow=n,ncol=K)\n",
    "  initZ = matrix(rnorm(n*K,0,1),ncol=K)\n",
    "  \n",
    "  res = .C(\"mcmcBayes\",sumMeanZ=as.double(meanZ),lastZ=as.double(initZ),acceptZ=as.integer(rep(0,n)),as.integer(c(n,K,zBurnin,zDraw,ndt,thin)),as.double(z.sdev),\n",
    "    as.integer(c(ty[1],p[1],C[1])),alpha1=as.double(a[[1]]),beta1=as.double(b[[1]]),as.double(con[[1]]),as.integer(cat[[1]]),sigma21=as.double(sigma2[[1]]),\n",
    "    as.integer(c(ty[2],p[2],C[2])),alpha2=as.double(a[[2]]),beta2=as.double(b[[2]]),as.double(con[[2]]),as.integer(cat[[2]]),sigma22=as.double(sigma2[[2]]),\n",
    "    as.integer(c(ty[3],p[3],C[3])),alpha3=as.double(a[[3]]),beta3=as.double(b[[3]]),as.double(con[[3]]),as.integer(cat[[3]]),sigma23=as.double(sigma2[[3]]),\n",
    "    as.integer(c(ty[4],p[4],C[4])),alpha4=as.double(a[[4]]),beta4=as.double(b[[4]]),as.double(con[[4]]),as.integer(cat[[4]]),sigma24=as.double(sigma2[[4]]),\n",
    "    as.integer(c(ty[5],p[5],C[5])),alpha5=as.double(a[[5]]),beta5=as.double(b[[5]]),as.double(con[[5]]),as.integer(cat[[5]]),sigma25=as.double(sigma2[[5]]),\n",
    "    as.integer(c(ty[6],p[6],C[6])),alpha6=as.double(a[[6]]),beta6=as.double(b[[6]]),as.double(con[[6]]),as.integer(cat[[6]]),sigma26=as.double(sigma2[[6]]),\n",
    "    as.integer(c(betaBurnin,betaDraw)),as.double(beta0),as.double(invSigma0),as.double(invSigmaBeta0),as.double(c(invga0,invgb0,betaVarScale)),as.double(pg),\n",
    "    sumGamma1=as.integer(gamma[[1]]),sumABeta1=as.integer(acceptBeta[[1]]),sumAGa1=as.integer(acceptGamma[[1]]),\n",
    "    sumGamma2=as.integer(gamma[[2]]),sumABeta2=as.integer(acceptBeta[[2]]),sumAGa2=as.integer(acceptGamma[[2]]),\n",
    "    sumGamma3=as.integer(gamma[[3]]),sumABeta3=as.integer(acceptBeta[[3]]),sumAGa3=as.integer(acceptGamma[[3]]),\n",
    "    sumGamma4=as.integer(gamma[[4]]),sumABeta4=as.integer(acceptBeta[[4]]),sumAGa4=as.integer(acceptGamma[[4]]),\n",
    "    sumGamma5=as.integer(gamma[[5]]),sumABeta5=as.integer(acceptBeta[[5]]),sumAGa5=as.integer(acceptGamma[[5]]),\n",
    "    sumGamma6=as.integer(gamma[[6]]),sumABeta6=as.integer(acceptBeta[[6]]),sumAGa6=as.integer(acceptGamma[[6]]),PACKAGE=\"iClusterPlus\")\n",
    "\n",
    "  Alpha = as.list(rep(NA,ndt))\n",
    "  Beta =  as.list(rep(NA,ndt))\n",
    "  Ratio =  as.list(rep(NA,ndt))\n",
    "  acsGamma =  as.list(rep(NA,ndt))\n",
    "  acsBeta =  as.list(rep(NA,ndt))\n",
    "  Sigma2 = as.list(rep(NA,ndt))\n",
    "\n",
    "  if(ndt >= 1){\n",
    "    Alpha[[1]] = res$alpha1\n",
    "    Beta[[1]] = matrix(res$beta1,ncol=K)\n",
    "    Sigma2[[1]] = res$sigma21\n",
    "    Ratio[[1]] = res$sumGamma1/betaDraw\n",
    "    acsGamma[[1]] = res$sumAGa1/betaDraw\n",
    "    acsBeta[[1]] = res$sumABeta1/betaDraw\n",
    "    if(ty[1] == 1){\n",
    "      acsBeta[[1]] = rep(1,p[1]) #normal data, acceptance ratio is always 1\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if(ndt >= 2){\n",
    "    Alpha[[2]] = res$alpha2\n",
    "    Beta[[2]] = matrix(res$beta2,ncol=K)\n",
    "    Sigma2[[2]] = res$sigma22\n",
    "    Ratio[[2]] = res$sumGamma2/betaDraw\n",
    "    acsGamma[[2]] = res$sumAGa2/betaDraw\n",
    "    acsBeta[[2]] = res$sumABeta2/betaDraw\n",
    "    if(ty[2] == 1){\n",
    "      acsBeta[[2]] = rep(1,p[2]) #normal data, acceptance ratio is always 1\n",
    "    }  \n",
    "  }\n",
    "\n",
    "  if(ndt >= 3){\n",
    "    Alpha[[3]] = res$alpha3\n",
    "    Beta[[3]] = matrix(res$beta3,ncol=K)\n",
    "    Sigma2[[3]] = res$sigma23\n",
    "    Ratio[[3]] = res$sumGamma3/betaDraw\n",
    "    acsGamma[[3]] = res$sumAGa3/betaDraw\n",
    "    acsBeta[[3]] = res$sumABeta3/betaDraw\n",
    "    if(ty[3] == 1){\n",
    "      acsBeta[[3]] = rep(1,p[3]) #normal data, acceptance ratio is always 1\n",
    "    }  \n",
    "  }\n",
    "\n",
    "  if(ndt >= 4){\n",
    "    Alpha[[4]] = res$alpha4\n",
    "    Beta[[4]] = matrix(res$beta4,ncol=K)\n",
    "    Sigma2[[4]] = res$sigma24\n",
    "    Ratio[[4]] = res$sumGamma4/betaDraw\n",
    "    acsGamma[[4]] = res$sumAGa4/betaDraw\n",
    "    acsBeta[[4]] = res$sumABeta4/betaDraw\n",
    "    if(ty[4] == 1){\n",
    "      acsBeta[[4]] = rep(1,p[4]) #normal data, acceptance ratio is always 1\n",
    "    }      \n",
    "  }\n",
    "\n",
    "  if(ndt >= 5){\n",
    "    Alpha[[5]] = res$alpha5\n",
    "    Beta[[5]] = matrix(res$beta5,ncol=K)\n",
    "    Sigma2[[5]] = res$sigma25\n",
    "    Ratio[[5]] = res$sumGamma5/betaDraw\n",
    "    acsGamma[[5]] = res$sumAGa5/betaDraw\n",
    "    acsBeta[[5]] = res$sumABeta5/betaDraw\n",
    "    if(ty[5] == 1){\n",
    "      acsBeta[[5]] = rep(1,p[5]) #normal data, acceptance ratio is always 1\n",
    "    }      \n",
    "  }\n",
    "\n",
    "  if(ndt >= 6){\n",
    "    Alpha[[6]] = res$alpha6\n",
    "    Beta[[6]] = matrix(res$beta6,ncol=K)\n",
    "    Sigma2[[6]] = res$sigma26\n",
    "    Ratio[[6]] = res$sumGamma6/betaDraw\n",
    "    acsGamma[[6]] = res$sumAGa6/betaDraw\n",
    "    acsBeta[[6]] = res$sumABeta6/betaDraw\n",
    "    if(ty[6] == 1){\n",
    "      acsBeta[[6]] = rep(1,p[6]) #normal data, acceptance ratio is always 1\n",
    "    }      \n",
    "  }\n",
    "  \n",
    "  list(meanZ=matrix(res$sumMeanZ,nrow=n,ncol=K),lastZ=matrix(res$lastZ,nrow=n,ncol=K),acsZ=res$acceptZ/zDraw/betaDraw,\n",
    "       Alpha=Alpha, Beta=Beta, Sigma2=Sigma2,Ratio=Ratio,acsGamma=acsGamma,acsBeta=acsBeta)\n",
    "}\n",
    "\n",
    "\n",
    "iClusterBayes <- function(dt1,dt2=NULL,dt3=NULL,dt4=NULL,dt5=NULL,dt6=NULL,type = c(\"gaussian\",\"binomial\",\"poisson\"),K=2,\n",
    "                          n.burnin=1000,n.draw=1200,prior.gamma=rep(0.1,6),sdev=0.5,beta.var.scale=1,thin=1,pp.cutoff=0.5){\n",
    "\n",
    "  dttype = c(\"gaussian\",\"binomial\",\"poisson\")\n",
    "  if(missing(dt1) | is.null(dt1)){\n",
    "    stop(\"Error: dt1 is missing!\\n\")\n",
    "  }\n",
    "\n",
    "  if(!all(type %in% dttype)){\n",
    "      cat(\"Error: \",type[!all(type %in% dttype)],\"\\n\")\n",
    "      stop(\"Allowed data types are gaussian, binomial and poisson. \\n\")\n",
    "  }\n",
    "\n",
    "  isNULL = c(is.null(dt1),is.null(dt2),is.null(dt3),is.null(dt4),is.null(dt5),is.null(dt6))\n",
    "  if(any(diff(isNULL) == -1)){\n",
    "      stop(\"Error: dt1 to dt6 must be assigned in order.\\n\")\n",
    "  }\n",
    "\n",
    " if(sum(!isNULL) > length(type)){\n",
    "     stop(\"Error:  data type is missing for some data. \\n\")\n",
    " } \n",
    "         \n",
    "  ### burnin and draw for latent variable Z ##\n",
    "  zBurnin = 0\n",
    "  zDraw = 1\n",
    "  ### the above settings make the draws for Z are the same as the draws for beta\n",
    "  ### if zDraw > 1, the outcome Z from mcmcMix will be the mean Z of zDraw\n",
    "  \n",
    "  ### n.burnin and n.draw control the overall draw for Z and parameter beta\n",
    "  betaBurnin = n.burnin\n",
    "  betaDraw = n.draw\n",
    "  \n",
    "  n = nrow(dt1)\n",
    "  ndt = 1\n",
    "  Data = list()\n",
    "  \n",
    "  Data[[1]] = dataType(dt1,type[1],K)\n",
    "   \n",
    "  Data[[2]] = NULL\n",
    "  if (!is.null(dt2)) {\n",
    "    if(n != nrow(dt2)){\n",
    "      stop(\"Error: nrow(dt1) != nrow(dt2) \\n\")\n",
    "    }    \n",
    "    Data[[2]] = dataType(dt2, type[2], K)\n",
    "    ndt = ndt + 1\n",
    "  }\n",
    "  \n",
    "  Data[[3]] = NULL\n",
    "  if(!is.null(dt3)){\n",
    "    if(n != nrow(dt3)){stop(\"Error: nrow(dt1) != nrow(dt3) \\n\")} \n",
    "    Data[[3]] = dataType(dt3,type[3],K)\n",
    "    ndt = ndt + 1\n",
    "  }\n",
    "  \n",
    "  Data[[4]] = NULL\n",
    "  if(!is.null(dt4)){\n",
    "    if(n != nrow(dt4)){stop(\"Error: nrow(dt1) != nrow(dt4) \\n\")} \n",
    "    Data[[4]] = dataType(dt4,type[4],K)\n",
    "    ndt = ndt + 1\n",
    "  }\n",
    "\n",
    "  Data[[5]] = NULL\n",
    "  if(!is.null(dt5)){\n",
    "    if(n != nrow(dt5)){stop(\"Error: nrow(dt1) != nrow(dt5) \\n\")} \n",
    "    Data[[5]] = dataType(dt5,type[5],K)\n",
    "    ndt = ndt + 1\n",
    "  }\n",
    "\n",
    "  Data[[6]] = NULL\n",
    "  if(!is.null(dt6)){\n",
    "      if(n != nrow(dt6)){stop(\"Error: nrow(dt1) != nrow(dt6) \\n\")} \n",
    "      Data[[6]] = dataType(dt6,type[6],K)\n",
    "      ndt = ndt + 1\n",
    "  }\n",
    "  ###### priors for Bayesian variable selection #######\n",
    "  invSigma0 = diag(rep(1,K+1))\n",
    "  beta0 = rep(0,K+1)\n",
    "  invSigmaBeta0 = invSigma0 %*% beta0\n",
    "  invga0=1\n",
    "  invgb0=1\n",
    "\n",
    "  res = mcmcBayes(dt1=Data[[1]],dt2=Data[[2]],dt3=Data[[3]],dt4=Data[[4]],dt5=Data[[5]],dt6=Data[[6]],ndt,sdev,n,K,zBurnin,zDraw,\n",
    "    betaBurnin, betaDraw,thin,prior.gamma,beta0,invSigma0,invSigmaBeta0,invga0,invgb0,beta.var.scale)\n",
    "\n",
    "  for(i in 1:ndt){\n",
    "    Data[[i]]$Alpha = res$Alpha[[i]]\n",
    "    Data[[i]]$Beta = res$Beta[[i]]\n",
    "    Data[[i]]$sigma2 = res$Sigma2[[i]]\n",
    "    Data[[i]]$Ratio = res$Ratio[[i]]\n",
    "    Data[[i]]$acsGamma = res$acsGamma\n",
    "    Data[[i]]$acsBeta = res$acsBeta\n",
    "  }\n",
    "  BIC = totalBICbayes(Data, res$meanZ, ndt, K, pp.cutoff)\n",
    "  devRatio = dev.ratio.bayes(Data, res$meanZ,ndt, K, pp.cutoff)\n",
    "  kmeans.fit = kmeans(res$meanZ, K + 1, nstart=100)\n",
    "  clusters = kmeans.fit$cluster\n",
    "  centers = kmeans.fit$centers\n",
    "  \n",
    "  list(alpha=res$Alpha, beta=res$Beta, beta.pp=res$Ratio,gamma.ar=res$acsGamma,beta.ar=res$acsBeta,Z.ar=res$acsZ,\n",
    "       clusters = clusters, centers = centers, meanZ = res$meanZ, BIC = BIC, dev.ratio = devRatio)\n",
    "}\n",
    "\n",
    "\n",
    "tune.iClusterBayes = function(cpus=6,dt1,dt2=NULL,dt3=NULL,dt4=NULL,dt5=NULL,dt6=NULL,type=c(\"gaussian\",\"binomial\",\"poisson\"),\n",
    "    K=1:6,n.burnin=1000,n.draw=1200,prior.gamma=rep(0.1,6),sdev=0.5,beta.var.scale=1,thin=1,pp.cutoff=0.5){\n",
    "\n",
    "  #require(parallel) \n",
    "  dttype = c(\"gaussian\",\"binomial\",\"poisson\")\n",
    "  if(missing(dt1) | is.null(dt1)){\n",
    "    stop(\"Error: dt1 is missing!\\n\")\n",
    "  }\n",
    "\n",
    "  if(!all(type %in% dttype)){\n",
    "      cat(\"Error: \",type[!all(type %in% dttype)],\"\\n\")\n",
    "      stop(\"Allowed data types are gaussian, binomial and poisson. \\n\")\n",
    "  }\n",
    "\n",
    "  isNULL = c(is.null(dt1),is.null(dt2),is.null(dt3),is.null(dt4),is.null(dt5),is.null(dt6))\n",
    "  if(any(diff(isNULL) == -1)){\n",
    "      stop(\"Error: dt1 to dt6 must be assigned in order.\\n\")\n",
    "  }\n",
    "\n",
    " if(sum(!isNULL) > length(type)){\n",
    "     stop(\"Error:  data type is missing for some data. \\n\")\n",
    " } \n",
    "          \n",
    "  cat(\"Begin parallel computation\\n\")\n",
    "  RNGkind(\"L'Ecuyer-CMRG\")\n",
    "  fit = mclapply(K,FUN=function(x)iClusterBayes(dt1,dt2,dt3,dt4,dt5,dt6,type,x,n.burnin,n.draw,prior.gamma,sdev,beta.var.scale,thin,pp.cutoff), \n",
    "       mc.silent=TRUE, mc.cores=cpus, mc.preschedule=FALSE)\n",
    "  cat(\"End parallel computation\\n\")\t\n",
    "\n",
    "  list(fit=fit)\n",
    "}\n",
    "\n",
    "\n",
    "plotHMBayes = function(fit, datasets, type = c(\"gaussian\", \"binomial\", \"poisson\"),\n",
    "    sample.order = NULL, row.order = NULL, sparse = NULL, \n",
    "    threshold = rep(0.5,length(datasets)), width = 5, scale = rep(\"none\",length(datasets)), \n",
    "    col.scheme = rep(list(bluered(256)),length(datasets)),chr=NULL, plot.chr=NULL, cap=NULL)\n",
    "{\n",
    "    m = length(datasets)\n",
    "    if(m > length(type)){\n",
    "        stop(\"Error:  data type is missing for some data. \\n\")        \n",
    "    }\n",
    "    \n",
    "    dttype = c(\"gaussian\",\"binomial\",\"poisson\")\n",
    "    if(!all(type %in% dttype)){\n",
    "        cat(\"Error: \",type[!all(type %in% dttype)],\"\\n\")\n",
    "        stop(\"Allowed data types are gaussian, binomial and poisson. \\n\")\n",
    "    }\n",
    "\n",
    "    if (is.null(row.order)) {\n",
    "        row.order = rep(T, m)\n",
    "    }\n",
    "    if (is.null(scale)) {\n",
    "        scale = rep(\"none\", m)\n",
    "    }\n",
    "    if (is.null(sparse)) {\n",
    "        sparse = rep(F, m)\n",
    "    }\n",
    "    if (is.null(cap)) {\n",
    "        cap = rep(F, m)\n",
    "    }\n",
    "    if (is.null(plot.chr)) {\n",
    "        plot.chr = rep(F, m)\n",
    "    }\n",
    "    clusters = fit$clusters\n",
    "    k = length(unique(clusters))\n",
    "    if (is.null(sample.order)) {\n",
    "        sorder = order(clusters)\n",
    "    }\n",
    "    else {\n",
    "        sorder = sample.order\n",
    "    }\n",
    "    m = length(datasets)\n",
    "    pp = unlist(lapply(1:m, function(l) {\n",
    "        dim(datasets[[l]])[2]\n",
    "    }))\n",
    "    n = dim(datasets[[1]])[1]\n",
    "    a = clusters[sorder]\n",
    "    l = length(a)\n",
    "    brkpoints = which(a[2:l] != a[1:(l - 1)])\n",
    "    cluster.start = c(1, brkpoints + 1)\n",
    "    my.panel.levelplot <- function(...) {\n",
    "        panel.levelplot(...)\n",
    "        panel.abline(v = (cluster.start[-1] - 0.5), col = \"black\", \n",
    "            lwd = 1, lty = 1)\n",
    "        panel.scales = list(draw = FALSE)\n",
    "    }\n",
    "    for (i in 1:m) {\n",
    "        pp = fit$beta.pp[[i]]\n",
    "        upper = threshold[i]\n",
    "        cat(i,\" \", sum(pp > upper),\"\\n\")\n",
    "        if (sparse[i] == T & sum(pp > upper) > 1) {\n",
    "            image.data = datasets[[i]][sorder, which(pp > upper)]\n",
    "        }else{\n",
    "             warning(\"No variable selected!\")\n",
    "              image.data = datasets[[i]][sorder, ]\n",
    "        }\n",
    "        if (row.order[i] == T) {\n",
    "            diss = 1 - cor(image.data, use = \"na.or.complete\")\n",
    "            hclust.fit = hclust(as.dist(diss))\n",
    "            gorder = hclust.fit$order\n",
    "            image.data = image.data[, gorder]\n",
    "        }\n",
    "        if (plot.chr[i] == T) {\n",
    "            if (sparse[i]) {\n",
    "                chr = chr[which(pp > upper)]\n",
    "            }\n",
    "            len = length(chr)\n",
    "            chrom.ends <- rep(NA, length(table(chr)))\n",
    "            d = 1\n",
    "            for (r in unique(chr)) {\n",
    "                chrom.ends[d] <- max(which(chr == r))\n",
    "                d = d + 1\n",
    "            }\n",
    "            chrom.starts <- c(1, chrom.ends[-length(table(chr))] + \n",
    "                1)\n",
    "            chrom.mids <- (chrom.starts + chrom.ends)/2\n",
    "            my.panel.levelplot.2 <- function(...) {\n",
    "                panel.levelplot(...)\n",
    "                panel.abline(v = (cluster.start[-1] - 0.5), col = \"black\", \n",
    "                  lwd = 1, lty = 1)\n",
    "                panel.abline(h = len - chrom.starts[-1], col = \"gray\", \n",
    "                  lwd = 1)\n",
    "                panel.scales = list(x = list(), y = list(at = len - \n",
    "                  chrom.mids), z = list())\n",
    "            }\n",
    "            my.panel = my.panel.levelplot.2\n",
    "            scales = list(x = list(draw = F), y = list(at = len - \n",
    "                chrom.mids, labels = names(table(chr))), z = list(draw = F))\n",
    "        }\n",
    "        else {\n",
    "            my.panel = my.panel.levelplot\n",
    "            scales = list(draw = F)\n",
    "        }\n",
    "        scale.fn = function(x) {\n",
    "            x <- sweep(x, 1L, rowMeans(x, na.rm = T), check.margin = T)\n",
    "            sx <- apply(x, 1L, sd, na.rm = T)\n",
    "            x <- sweep(x, 1L, sx, \"/\", check.margin = T)\n",
    "            return(x)\n",
    "        }\n",
    "        if (scale[i] == \"row\") {\n",
    "            image.data = scale.fn(image.data)\n",
    "        }\n",
    "        if (scale[i] == \"col\") {\n",
    "            image.data = scale.fn(t(image.data))\n",
    "            image.data = t(image.data)\n",
    "        }\n",
    "        image.data = as.matrix(rev(as.data.frame(image.data)))\n",
    "        if (type[i] == \"binomial\") {\n",
    "            colorkey = list(space = \"right\", height = 0.3, at = c(0, \n",
    "                0.5, 1), tick.number = 1)\n",
    "        }\n",
    "        else {\n",
    "            colorkey = list(space = \"right\", height = 0.3, tick.number = 5)\n",
    "        }\n",
    "        if (cap[i] == T) {\n",
    "            cut = quantile(datasets[[i]], prob = 0.9995, na.rm = T)\n",
    "            p = levelplot(image.data, panel = my.panel, scales = scales, \n",
    "                col.regions = col.scheme[[i]], at = c(-Inf, seq(-cut, \n",
    "                  cut, length = 256), Inf), xlab = \"\", ylab = \"\", \n",
    "                colorkey = colorkey)\n",
    "        }\n",
    "        else {\n",
    "            p = levelplot(image.data, panel = my.panel, scales = scales, \n",
    "                col.regions = col.scheme[[i]], xlab = \"\", ylab = \"\", \n",
    "                colorkey = colorkey)\n",
    "        }\n",
    "        if (i == m) {\n",
    "            print(p, split = c(1, i, 1, m), more = F, panel.width = list(width, \n",
    "                \"inches\"))\n",
    "        }\n",
    "        else {\n",
    "            print(p, split = c(1, i, 1, m), more = T, panel.width = list(width, \n",
    "                \"inches\"))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "########### deviance ratio function using glmnet functions ############\n",
    "dev.ratio.bayes0 = function(Data,meanZ,ndt,K){\n",
    "  cat(\"- deviance ratio -\\n\")\n",
    "  alpha = rep(1,ndt)\n",
    "  lambda = rep(0,ndt) #set all lambda to zero because no-significant variables will be removed\n",
    "  sumdev0 = 0\n",
    "  sumdev = 0\n",
    "  for(i in 1:ndt){\n",
    "    #sigID = which(Data[[i]]$Ratio >= quantile(Data[[i]]$Ratio,prob=0.9))\n",
    "    sigID = which(Data[[i]]$Ratio > 0.5)\n",
    "    lenp = length(sigID)\n",
    "    lenp0 = length(Data[[i]]$Ratio) - lenp\n",
    "    if(Data[[i]]$type == 1){  # normal #\n",
    "        if(lenp > 0){\n",
    "            fit1 = .C(\"elnetBatchDev\",a0=double(lenp),beta=double(lenp*K),sigma2 = double(lenp),\n",
    "                as.double(meanZ),as.double(Data[[i]]$con[,sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp),\n",
    "                as.double(alpha[i]),as.double(lambda[i]),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\")\n",
    "            cat(fit1$sumdev0, fit1$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit1$sumdev0\n",
    "            sumdev = sumdev + fit1$sumdev\n",
    "        }\n",
    "        if(lenp0 > 0){    \n",
    "            fit1 = .C(\"elnetBatchDev\",a0=double(lenp0),beta=double(lenp0*K),sigma2 = double(lenp0),\n",
    "                as.double(meanZ),as.double(Data[[i]]$con[,-sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp0),\n",
    "                as.double(alpha[i]),as.double(1),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\")\n",
    "            cat(fit1$sumdev0, fit1$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit1$sumdev0\n",
    "            sumdev = sumdev + fit1$sumdev\n",
    "        }\n",
    "    }else if(Data[[i]]$type == 2){ # binomial #\n",
    "        if(lenp > 0){   \n",
    "            fit2 = .C(\"lognetBatchDev\",a0=double(lenp),beta=double(lenp*K),as.double(meanZ),\n",
    "                as.integer(Data[[i]]$cat[,sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp),\n",
    "                as.double(alpha[i]),as.double(lambda[i]),as.integer(Data[[i]]$nclass),as.integer(2),\n",
    "                as.integer(0),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\") #family=0 is binomial\n",
    "            cat(fit2$sumdev0, fit2$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit2$sumdev0\n",
    "            sumdev = sumdev + fit2$sumdev\n",
    "        }\n",
    "        if(lenp0 > 0){\n",
    "            fit2 = .C(\"lognetBatchDev\",a0=double(lenp0),beta=double(lenp0*K),as.double(meanZ),\n",
    "                as.integer(Data[[i]]$cat[,-sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp0),\n",
    "                as.double(alpha[i]),as.double(1),as.integer(Data[[i]]$nclass),as.integer(2),\n",
    "                as.integer(0),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\") #family=0 is binomial\n",
    "            cat(fit2$sumdev0, fit2$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit2$sumdev0\n",
    "            sumdev = sumdev + fit2$sumdev\n",
    "        }\n",
    "    }else if(Data[[i]]$type == 3){ # Poisson #\n",
    "        if(lenp > 0){        \n",
    "            fit3 = .C(\"fishnetBatchDev\",a0=double(lenp),beta=double(lenp*K),as.double(meanZ),\n",
    "                as.double(Data[[i]]$cat[,sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp),\n",
    "                as.double(alpha[i]),as.double(lambda[i]),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\")\n",
    "            cat(fit3$sumdev0, fit3$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit3$sumdev0\n",
    "            sumdev = sumdev + fit3$sumdev\n",
    "        }\n",
    "        if(lenp0 > 0){\n",
    "            fit3 = .C(\"fishnetBatchDev\",a0=double(lenp0),beta=double(lenp0*K),as.double(meanZ),\n",
    "                as.double(Data[[i]]$cat[,-sigID]),as.integer(Data[[i]]$n),as.integer(K),as.integer(lenp0),\n",
    "                as.double(alpha[i]),as.double(1),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\")\n",
    "            cat(fit3$sumdev0, fit3$sumdev,\"\\n\")\n",
    "            sumdev0 = sumdev0 + fit3$sumdev0\n",
    "            sumdev = sumdev + fit3$sumdev\n",
    "        }\n",
    "      }else { # Multinomial #\n",
    "       # fit4 = .C(\"lognetBatchDev\",a0=double(lenp * Data[[i]]$C),beta=double(lenp*K*Data[[i]]$C),\n",
    "       #   as.double(meanZ),as.integer(Data[[i]]$cat[,sigID]),as.integer(Data[[i]]$n),as.integer(K),\n",
    "       #   as.integer(lenp),as.double(alpha[i]),as.double(lambda[i]),as.integer(Data[[i]]$nclass),\n",
    "       #   as.integer(Data[[i]]$C),as.integer(1),sumdev0=double(1),sumdev=double(1))# =\"iClusterPlus\") #family=1 is multinomial\n",
    "       # sumdev0 = sumdev0 + fit4$sumdev0\n",
    "       # sumdev = sumdev + fit4$sumdev\n",
    "      }\n",
    "  }\n",
    "  # deviance ratio, for linear reg, it is R-square; the bigger, the better\n",
    "  1-sumdev/sumdev0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bf46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cNMF\n",
    "ExecuteCNMF<-function(datasets, clusterNum,nrun=30 )\n",
    "{\n",
    "  if(is.list(datasets))\n",
    "  {\n",
    "    temp=NULL\n",
    "    for(i in 1: length(datasets))\n",
    "    {\n",
    "      temp=rbind(temp,datasets[[i]])\n",
    "    }\n",
    "  }\n",
    "  else\n",
    "    temp=datasets\n",
    "  ## change all value to positive\n",
    "  data1=rbind(pmax(temp,0),-pmin(temp,0))\n",
    "  index=which(rowSums(data1)==0)\n",
    "  data1=data1[-index,]\n",
    "  res=nmf(data1,rank=clusterNum,nrun=nrun)\n",
    "  \n",
    "  distanceMatrix=slot(res,\"consensus\")\n",
    "  attr(distanceMatrix,'class')=\"Similarity\"\n",
    "  \n",
    "  group=as.numeric(as.vector(predict(res)))\n",
    "  result=list(group=group,distanceMatrix=distanceMatrix,originalResult=res)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
